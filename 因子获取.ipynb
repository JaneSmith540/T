{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# api设置",
   "id": "a76ac198a3e3d15c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-14T05:55:37.247287Z",
     "start_time": "2025-11-14T05:55:36.643869Z"
    }
   },
   "source": [
    "import math\n",
    "from utils import *\n",
    "import tushare as ts\n",
    "\n",
    "def read_tushare_token():\n",
    "    try:\n",
    "        with open('tushare_token.txt', 'r', encoding='utf-8') as file:\n",
    "            token = file.read().strip()\n",
    "            return token\n",
    "    except FileNotFoundError:\n",
    "        print(\"tushare_token.txt 文件未找到\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"读取文件时出错: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "TUSHARE_TOKEN = read_tushare_token()\n",
    "\n",
    "pro = ts.pro_api(TUSHARE_TOKEN)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 获取股票池",
   "id": "68976cd25926e868"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T05:55:39.395578Z",
     "start_time": "2025-11-14T05:55:39.375572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tushare as ts\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_stock_data():\n",
    "    # 读取中证500成分股数据\n",
    "    # 数据文件路径\n",
    "    file_path = r\"D:\\read\\task\\中证500成分股,单一股票数据.csv\"\n",
    "    # 读取CSV文件，注意处理带引号的字段\n",
    "    df = pd.read_csv(file_path, dtype=str)  # 先都按字符串读取，避免格式问题\n",
    "    # 获取股票代码列表\n",
    "    stock_codes = df['con_code'].unique()\n",
    "    print (stock_codes)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    get_stock_data()"
   ],
   "id": "6555de20d32ff239",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['300476.SZ' '000988.SZ' '300450.SZ' '688521.SH' '300207.SZ' '600580.SH'\n",
      " '300803.SZ' '002156.SZ' '600988.SH' '300339.SZ' '002558.SZ' '002195.SZ'\n",
      " '600487.SH' '002340.SZ' '688072.SH' '600143.SH' '688525.SH' '600021.SH'\n",
      " '002517.SZ' '002837.SZ' '002738.SZ' '601168.SH' '000831.SZ' '300857.SZ'\n",
      " '000933.SZ' '601555.SH' '000426.SZ' '603893.SH' '600839.SH' '002532.SZ'\n",
      " '601162.SH' '002966.SZ' '300604.SZ' '600096.SH' '002436.SZ' '300115.SZ'\n",
      " '688027.SH' '600157.SH' '600885.SH' '688122.SH' '689009.SH' '002273.SZ'\n",
      " '002008.SZ' '300136.SZ' '002850.SZ' '600895.SH' '002261.SZ' '688235.SH'\n",
      " '600549.SH' '688120.SH' '002851.SZ' '002294.SZ' '301358.SZ' '300454.SZ'\n",
      " '688777.SH' '301308.SZ' '300395.SZ' '000066.SZ' '600392.SH' '002202.SZ'\n",
      " '002797.SZ' '600673.SH' '688469.SH' '600699.SH' '603659.SH' '002185.SZ'\n",
      " '002138.SZ' '601099.SH' '002353.SZ' '002281.SZ' '688002.SH' '300073.SZ'\n",
      " '688213.SH' '000021.SZ' '002472.SZ' '600536.SH' '300223.SZ' '000783.SZ'\n",
      " '688099.SH' '600879.SH' '688608.SH' '603228.SH' '300017.SZ' '002130.SZ'\n",
      " '601108.SH' '300037.SZ' '601615.SH' '600352.SH' '300346.SZ' '603129.SH'\n",
      " '688183.SH' '688249.SH' '300748.SZ' '002595.SZ' '300054.SZ' '300458.SZ'\n",
      " '603179.SH' '300724.SZ' '601717.SH' '601665.SH' '300058.SZ' '603606.SH'\n",
      " '600109.SH' '600118.SH' '000878.SZ' '002085.SZ' '300496.SZ' '300251.SZ'\n",
      " '601198.SH' '603979.SH' '603087.SH' '000034.SZ' '002410.SZ' '688578.SH'\n",
      " '600079.SH' '300012.SZ' '000932.SZ' '300003.SZ' '601233.SH' '688361.SH'\n",
      " '300002.SZ' '002078.SZ' '002414.SZ' '002155.SZ' '300474.SZ' '600298.SH'\n",
      " '688220.SH' '601128.SH' '601696.SH' '000960.SZ' '688617.SH' '002465.SZ'\n",
      " '002080.SZ' '002624.SZ' '000893.SZ' '002065.SZ' '601577.SH' '300024.SZ'\n",
      " '002673.SZ' '000728.SZ' '600363.SH' '300373.SZ' '603160.SH' '300757.SZ'\n",
      " '600873.SH' '600141.SH' '002409.SZ' '002444.SZ' '688180.SH' '600884.SH'\n",
      " '002223.SZ' '300919.SZ' '300001.SZ' '000423.SZ' '603596.SH' '601933.SH'\n",
      " '000009.SZ' '600497.SH' '000623.SZ' '603486.SH' '000750.SZ' '688385.SH'\n",
      " '000997.SZ' '002821.SZ' '300383.SZ' '600637.SH' '000733.SZ' '300142.SZ'\n",
      " '600171.SH' '600060.SH' '300763.SZ' '605589.SH' '002653.SZ' '688676.SH'\n",
      " '600369.SH' '605358.SH' '000528.SZ' '300285.SZ' '600862.SH' '000400.SZ'\n",
      " '601990.SH' '600909.SH' '600498.SH' '688065.SH' '600208.SH' '002683.SZ'\n",
      " '600704.SH' '688772.SH' '000887.SZ' '688017.SH' '300677.SZ' '002064.SZ'\n",
      " '601997.SH' '002939.SZ' '600153.SH' '300390.SZ' '002007.SZ' '002044.SZ'\n",
      " '000683.SZ' '603605.SH' '300627.SZ' '002841.SZ' '601216.SH' '002318.SZ'\n",
      " '600521.SH' '600177.SH' '600516.SH' '002056.SZ' '688052.SH' '688778.SH'\n",
      " '300699.SZ' '600737.SH' '000559.SZ' '688568.SH' '000729.SZ' '001696.SZ'\n",
      " '600155.SH' '601179.SH' '600563.SH' '000723.SZ' '002152.SZ' '601611.SH'\n",
      " '002756.SZ' '600486.SH' '002926.SZ' '601231.SH' '688188.SH' '002203.SZ'\n",
      " '601212.SH' '000830.SZ' '000415.SZ' '000519.SZ' '002262.SZ' '603345.SH'\n",
      " '603816.SH' '600435.SH' '688538.SH' '600499.SH' '600170.SH' '603298.SH'\n",
      " '600765.SH' '688702.SH' '002603.SZ' '300679.SZ' '600398.SH' '300765.SZ'\n",
      " '603568.SH' '600316.SH' '600038.SH' '603939.SH' '000738.SZ' '000703.SZ'\n",
      " '300751.SZ' '300567.SZ' '600095.SH' '000039.SZ' '601958.SH' '600801.SH'\n",
      " '600820.SH' '300623.SZ' '600348.SH' '000060.SZ' '300558.SZ' '600312.SH'\n",
      " '002958.SZ' '600985.SH' '600166.SH' '002385.SZ' '600901.SH' '600562.SH'\n",
      " '603156.SH' '600008.SH' '000629.SZ' '300487.SZ' '600863.SH' '002739.SZ'\n",
      " '600529.SH' '002429.SZ' '601608.SH' '002500.SZ' '300573.SZ' '688301.SH'\n",
      " '603379.SH' '688114.SH' '000636.SZ' '002430.SZ' '600763.SH' '000155.SZ'\n",
      " '603077.SH' '601991.SH' '002432.SZ' '002607.SZ' '603338.SH' '600380.SH'\n",
      " '000513.SZ' '600390.SH' '002244.SZ' '002568.SZ' '603737.SH' '600282.SH'\n",
      " '600132.SH' '600998.SH' '600329.SH' '688582.SH' '601155.SH' '000591.SZ'\n",
      " '601880.SH' '300146.SZ' '601001.SH' '601666.SH' '600970.SH' '002312.SZ'\n",
      " '300144.SZ' '002773.SZ' '603290.SH' '688728.SH' '300676.SZ' '603728.SH'\n",
      " '600126.SH' '603927.SH' '002025.SZ' '600378.SH' '600995.SH' '002670.SZ'\n",
      " '603225.SH' '000987.SZ' '688234.SH' '002984.SZ' '600583.SH' '601016.SH'\n",
      " '000050.SZ' '688278.SH' '000921.SZ' '300735.SZ' '601000.SH' '600816.SH'\n",
      " '002423.SZ' '600739.SH' '603589.SH' '000062.SZ' '600004.SH' '600535.SH'\n",
      " '300601.SZ' '601456.SH' '002439.SZ' '603885.SH' '601636.SH' '600859.SH'\n",
      " '600872.SH' '601918.SH' '601966.SH' '600511.SH' '600483.SH' '603688.SH'\n",
      " '000563.SZ' '603000.SH' '600685.SH' '600517.SH' '688318.SH' '600131.SH'\n",
      " '600546.SH' '600325.SH' '600655.SH' '600848.SH' '600977.SH' '688561.SH'\n",
      " '000951.SZ' '002266.SZ' '000958.SZ' '601598.SH' '002507.SZ' '600867.SH'\n",
      " '002120.SZ' '000598.SZ' '002299.SZ' '000403.SZ' '688363.SH' '603341.SH'\n",
      " '000709.SZ' '601333.SH' '003031.SZ' '300212.SZ' '600754.SH' '603899.SH'\n",
      " '601866.SH' '600598.SH' '601399.SH' '600663.SH' '601156.SH' '002831.SZ'\n",
      " '000027.SZ' '301536.SZ' '600582.SH' '603650.SH' '600808.SH' '688297.SH'\n",
      " '600258.SH' '300529.SZ' '601118.SH' '600578.SH' '688520.SH' '300888.SZ'\n",
      " '603858.SH' '000825.SZ' '300070.SZ' '600906.SH' '000032.SZ' '600528.SH'\n",
      " '603565.SH' '000543.SZ' '600271.SH' '600566.SH' '002508.SZ' '000883.SZ'\n",
      " '600871.SH' '600959.SH' '000739.SZ' '688248.SH' '300595.SZ' '688387.SH'\n",
      " '601106.SH' '601098.SH' '600764.SH' '000967.SZ' '688425.SH' '600056.SH'\n",
      " '600707.SH' '603529.SH' '603233.SH' '000582.SZ' '600062.SH' '002153.SZ'\n",
      " '003022.SZ' '600968.SH' '688281.SH' '601928.SH' '301301.SZ' '300957.SZ'\n",
      " '002572.SZ' '600606.SH' '001286.SZ' '600098.SH' '000785.SZ' '600373.SH'\n",
      " '000537.SZ' '688563.SH' '301165.SZ' '688172.SH' '601965.SH' '688349.SH'\n",
      " '600361.SH' '600925.SH' '603556.SH' '601061.SH' '603658.SH' '600295.SH'\n",
      " '000959.SZ' '002372.SZ' '000937.SZ' '000898.SZ' '601568.SH' '603786.SH'\n",
      " '002608.SZ' '600612.SH' '600688.SH' '000429.SZ' '600339.SH' '301498.SZ'\n",
      " '601139.SH' '600032.SH' '003035.SZ' '688100.SH' '688375.SH' '600720.SH'\n",
      " '688032.SH' '601019.SH' '600928.SH' '601228.SH' '688475.SH' '301267.SZ'\n",
      " '603707.SH' '688819.SH' '600927.SH' '002563.SZ' '002945.SZ' '000539.SZ'\n",
      " '600007.SH' '002461.SZ' '300140.SZ' '001213.SZ' '600299.SH' '603826.SH'\n",
      " '601921.SH' '688153.SH' '601858.SH' '001389.SZ' '601158.SH' '688295.SH'\n",
      " '600956.SH' '603868.SH']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "获取weight",
   "id": "15e5173c7c23f9f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T06:06:41.885540Z",
     "start_time": "2025-11-14T06:06:26.273241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "        ts_code trade_date      close       open       high        low  \\\n",
    "0     000905.SH   20250630  5915.3876  5877.6748  5918.3068  5872.2251   \n",
    "1     000905.SH   20250627  5863.7282  5850.4252  5905.6962  5839.5775   \n",
    "2     000905.SH   20250626  5838.2454  5868.2924  5885.2508  5835.3395   \n",
    "3     000905.SH   20250625  5862.5529  5777.7404  5866.5246  5776.1237   \n",
    "4     000905.SH   20250624  5765.8373  5683.4622  5766.0189  5683.4622   \n",
    "...         ...        ...        ...        ...        ...        ...   \n",
    "1811  000905.SH   20180108  6446.1818  6413.8733  6446.7879  6393.8819   \n",
    "1812  000905.SH   20180105  6417.2537  6414.7658  6435.8540  6397.2929   \n",
    "1813  000905.SH   20180104  6417.5350  6380.2665  6418.2560  6375.5134   \n",
    "1814  000905.SH   20180103  6388.2533  6331.7199  6391.9799  6324.2604   \n",
    "1815  000905.SH   20180102  6332.2269  6263.1506  6332.6089  6258.1563   \n",
    "\n",
    "      pre_close   change  pct_chg          vol        amount  \n",
    "0     5863.7282  51.6594   0.8810  166275147.0  2.265167e+08  \n",
    "1     5838.2454  25.4828   0.4365  199389725.0  2.433030e+08  \n",
    "2     5862.5529 -24.3075  -0.4146  180164163.0  2.352237e+08  \n",
    "3     5765.8373  96.7156   1.6774  184632310.0  2.392604e+08  \n",
    "4     5674.1704  91.6669   1.6155  142082256.0  1.919355e+08  \n",
    "\"\"\""
   ],
   "id": "f321a8a573220384",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理第 1/10 批股票...\n",
      "正在处理第 2/10 批股票...\n",
      "正在处理第 3/10 批股票...\n",
      "正在处理第 4/10 批股票...\n",
      "正在处理第 5/10 批股票...\n",
      "正在处理第 6/10 批股票...\n",
      "正在处理第 7/10 批股票...\n",
      "正在处理第 8/10 批股票...\n",
      "正在处理第 9/10 批股票...\n",
      "正在处理第 10/10 批股票...\n",
      "未能获取到数据\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T06:27:38.235631Z",
     "start_time": "2025-11-14T06:27:37.898258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取CSV文件\n",
    "file_path = r\"C:\\Users\\chanpi\\Desktop\\task\\中证500成分股,单一股票数据.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 按权重降序排序\n",
    "df_sorted = df.sort_values(by='weight', ascending=False)\n",
    "\n",
    "# 显示按权重排序后的数据\n",
    "print(df_sorted)\n"
   ],
   "id": "fd84b442ef58680",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index_code   con_code  weight  trade_date\n",
      "0    000905.SH  300476.SZ   1.944  2025-10-31\n",
      "1    000905.SH  000988.SZ   0.879  2025-10-31\n",
      "2    000905.SH  300450.SZ   0.703  2025-10-31\n",
      "3    000905.SH  688521.SH   0.612  2025-10-31\n",
      "4    000905.SH  300207.SZ   0.580  2025-10-31\n",
      "..         ...        ...     ...         ...\n",
      "495  000905.SH  001389.SZ   0.031  2025-10-31\n",
      "496  000905.SH  601158.SH   0.030  2025-10-31\n",
      "497  000905.SH  688295.SH   0.028  2025-10-31\n",
      "498  000905.SH  600956.SH   0.027  2025-10-31\n",
      "499  000905.SH  603868.SH   0.019  2025-10-31\n",
      "\n",
      "[500 rows x 4 columns]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T06:39:07.461199Z",
     "start_time": "2025-11-14T06:39:06.381556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 读取权重数据\n",
    "weight_file_path = r\"C:\\Users\\chanpi\\Desktop\\task\\中证500成分股,单一股票数据.csv\"\n",
    "df_weights = pd.read_csv(weight_file_path)\n",
    "\n",
    "# 按权重降序排序\n",
    "df_weights_sorted = df_weights.sort_values(by='weight', ascending=False)\n",
    "print(\"权重数据:\")\n",
    "print(df_weights_sorted.head())\n",
    "\n",
    "# 读取股票数据\n",
    "stock_file_path = r\"C:\\Users\\chanpi\\Desktop\\task\\赋权后数据.pkl\"\n",
    "df_stocks = pd.read_pickle(stock_file_path)\n",
    "print(\"\\n股票数据形状:\", df_stocks.shape)\n",
    "print(\"股票数据列名:\", df_stocks.columns.tolist())\n",
    "\n",
    "# 确保权重数据和股票数据的股票代码格式一致\n",
    "# 获取权重数据中的所有股票代码\n",
    "weight_stocks = df_weights_sorted['con_code'].unique()\n",
    "print(f\"\\n权重数据中的股票数量: {len(weight_stocks)}\")\n",
    "\n",
    "# 获取股票数据中的所有股票代码\n",
    "available_stocks = df_stocks['ts_code'].unique()\n",
    "print(f\"股票数据中的股票数量: {len(available_stocks)}\")\n",
    "\n",
    "# 找出共同存在的股票\n",
    "common_stocks = set(weight_stocks) & set(available_stocks)\n",
    "print(f\"共同存在的股票数量: {len(common_stocks)}\")\n",
    "\n",
    "if len(common_stocks) == 0:\n",
    "    print(\"警告: 没有找到共同的股票代码!\")\n",
    "    # 检查格式差异\n",
    "    print(\"权重数据股票代码示例:\", list(weight_stocks[:5]))\n",
    "    print(\"股票数据代码示例:\", list(available_stocks[:5]))\n",
    "else:\n",
    "    print(\"共同股票示例:\", list(common_stocks)[:5])\n",
    "\n",
    "# 过滤权重数据，只保留有数据的股票\n",
    "df_weights_filtered = df_weights_sorted[df_weights_sorted['con_code'].isin(common_stocks)]\n",
    "\n",
    "# 重新计算权重，使其总和为1\n",
    "total_weight = df_weights_filtered['weight'].sum()\n",
    "df_weights_filtered['weight_normalized'] = df_weights_filtered['weight'] / total_weight\n",
    "print(f\"\\n归一化后权重总和: {df_weights_filtered['weight_normalized'].sum():.6f}\")\n",
    "\n",
    "# 合并权重数据和股票数据\n",
    "df_merged = pd.merge(df_stocks, df_weights_filtered, \n",
    "                    left_on='ts_code', right_on='con_code', \n",
    "                    how='inner')\n",
    "\n",
    "print(f\"\\n合并后数据形状: {df_merged.shape}\")\n",
    "\n",
    "# 计算资产组合的每日加权指标\n",
    "numeric_columns = ['close', 'open', 'high', 'low', 'pre_close', 'change', 'pct_chg', 'vol', 'amount']\n",
    "\n",
    "# 按日期分组计算加权平均\n",
    "portfolio_daily = df_merged.groupby('trade_date').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'close': np.average(x['close'], weights=x['weight_normalized']),\n",
    "        'open': np.average(x['open'], weights=x['weight_normalized']),\n",
    "        'high': np.average(x['high'], weights=x['weight_normalized']),\n",
    "        'low': np.average(x['low'], weights=x['weight_normalized']),\n",
    "        'pre_close': np.average(x['pre_close'], weights=x['weight_normalized']),\n",
    "        'change': np.average(x['change'], weights=x['weight_normalized']),\n",
    "        'pct_chg': np.average(x['pct_chg'], weights=x['weight_normalized']),\n",
    "        'vol': np.average(x['vol'], weights=x['weight_normalized']),\n",
    "        'amount': np.average(x['amount'], weights=x['weight_normalized']),\n",
    "        'constituent_count': len(x)  # 包含的成分股数量\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "# 按日期排序\n",
    "portfolio_daily = portfolio_daily.sort_values('trade_date')\n",
    "\n",
    "print(f\"\\n资产组合数据形状: {portfolio_daily.shape}\")\n",
    "print(\"\\n资产组合前5行数据:\")\n",
    "print(portfolio_daily.head())\n",
    "\n",
    "print(\"\\n资产组合后5行数据:\")\n",
    "print(portfolio_daily.tail())\n",
    "\n",
    "# 保存结果\n",
    "output_path = r\"C:\\Users\\chanpi\\Desktop\\task\\资产组合每日数据.csv\"\n",
    "portfolio_daily.to_csv(output_path, index=False)\n",
    "print(f\"\\n结果已保存至: {output_path}\")\n",
    "\n",
    "# 显示一些统计信息\n",
    "print(\"\\n资产组合统计信息:\")\n",
    "print(f\"时间范围: {portfolio_daily['trade_date'].min()} 到 {portfolio_daily['trade_date'].max()}\")\n",
    "print(f\"总交易日数: {len(portfolio_daily)}\")\n",
    "print(f\"平均每日成分股数量: {portfolio_daily['constituent_count'].mean():.1f}\")\n",
    "print(f\"最终组合收盘价: {portfolio_daily['close'].iloc[-1]:.2f}\")\n"
   ],
   "id": "841cf7638e4a3048",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "权重数据:\n",
      "  index_code   con_code  weight  trade_date\n",
      "0  000905.SH  300476.SZ   1.944  2025-10-31\n",
      "1  000905.SH  000988.SZ   0.879  2025-10-31\n",
      "2  000905.SH  300450.SZ   0.703  2025-10-31\n",
      "3  000905.SH  688521.SH   0.612  2025-10-31\n",
      "4  000905.SH  300207.SZ   0.580  2025-10-31\n",
      "\n",
      "股票数据形状: (813507, 11)\n",
      "股票数据列名: ['ts_code', 'trade_date', 'open', 'high', 'low', 'close', 'pre_close', 'change', 'pct_chg', 'vol', 'amount']\n",
      "\n",
      "权重数据中的股票数量: 500\n",
      "股票数据中的股票数量: 500\n",
      "共同存在的股票数量: 500\n",
      "共同股票示例: ['000513.SZ', '300395.SZ', '002532.SZ', '002624.SZ', '601966.SH']\n",
      "\n",
      "归一化后权重总和: 1.000000\n",
      "\n",
      "合并后数据形状: (813507, 16)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'trade_date'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 59\u001B[0m\n\u001B[0;32m     56\u001B[0m numeric_columns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclose\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mopen\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhigh\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlow\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpre_close\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchange\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpct_chg\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvol\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mamount\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     58\u001B[0m \u001B[38;5;66;03m# 按日期分组计算加权平均\u001B[39;00m\n\u001B[1;32m---> 59\u001B[0m portfolio_daily \u001B[38;5;241m=\u001B[39m \u001B[43mdf_merged\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupby\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrade_date\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mapply(\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m x: pd\u001B[38;5;241m.\u001B[39mSeries({\n\u001B[0;32m     61\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclose\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39maverage(x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclose\u001B[39m\u001B[38;5;124m'\u001B[39m], weights\u001B[38;5;241m=\u001B[39mx[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweight_normalized\u001B[39m\u001B[38;5;124m'\u001B[39m]),\n\u001B[0;32m     62\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mopen\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39maverage(x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mopen\u001B[39m\u001B[38;5;124m'\u001B[39m], weights\u001B[38;5;241m=\u001B[39mx[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweight_normalized\u001B[39m\u001B[38;5;124m'\u001B[39m]),\n\u001B[0;32m     63\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhigh\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39maverage(x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhigh\u001B[39m\u001B[38;5;124m'\u001B[39m], weights\u001B[38;5;241m=\u001B[39mx[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweight_normalized\u001B[39m\u001B[38;5;124m'\u001B[39m]),\n\u001B[0;32m     64\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlow\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39maverage(x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlow\u001B[39m\u001B[38;5;124m'\u001B[39m], weights\u001B[38;5;241m=\u001B[39mx[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweight_normalized\u001B[39m\u001B[38;5;124m'\u001B[39m]),\n\u001B[0;32m     65\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpre_close\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39maverage(x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpre_close\u001B[39m\u001B[38;5;124m'\u001B[39m], weights\u001B[38;5;241m=\u001B[39mx[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweight_normalized\u001B[39m\u001B[38;5;124m'\u001B[39m]),\n\u001B[0;32m     66\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchange\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39maverage(x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchange\u001B[39m\u001B[38;5;124m'\u001B[39m], weights\u001B[38;5;241m=\u001B[39mx[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweight_normalized\u001B[39m\u001B[38;5;124m'\u001B[39m]),\n\u001B[0;32m     67\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpct_chg\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39maverage(x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpct_chg\u001B[39m\u001B[38;5;124m'\u001B[39m], weights\u001B[38;5;241m=\u001B[39mx[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweight_normalized\u001B[39m\u001B[38;5;124m'\u001B[39m]),\n\u001B[0;32m     68\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvol\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39maverage(x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvol\u001B[39m\u001B[38;5;124m'\u001B[39m], weights\u001B[38;5;241m=\u001B[39mx[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweight_normalized\u001B[39m\u001B[38;5;124m'\u001B[39m]),\n\u001B[0;32m     69\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mamount\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39maverage(x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mamount\u001B[39m\u001B[38;5;124m'\u001B[39m], weights\u001B[38;5;241m=\u001B[39mx[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweight_normalized\u001B[39m\u001B[38;5;124m'\u001B[39m]),\n\u001B[0;32m     70\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconstituent_count\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mlen\u001B[39m(x)  \u001B[38;5;66;03m# 包含的成分股数量\u001B[39;00m\n\u001B[0;32m     71\u001B[0m     })\n\u001B[0;32m     72\u001B[0m )\u001B[38;5;241m.\u001B[39mreset_index()\n\u001B[0;32m     74\u001B[0m \u001B[38;5;66;03m# 按日期排序\u001B[39;00m\n\u001B[0;32m     75\u001B[0m portfolio_daily \u001B[38;5;241m=\u001B[39m portfolio_daily\u001B[38;5;241m.\u001B[39msort_values(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrade_date\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mC:\\ana\\envs\\XGboost\\lib\\site-packages\\pandas\\core\\frame.py:9183\u001B[0m, in \u001B[0;36mDataFrame.groupby\u001B[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001B[0m\n\u001B[0;32m   9180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m level \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m by \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   9181\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou have to supply one of \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mby\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m and \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlevel\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 9183\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataFrameGroupBy\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   9184\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   9185\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mby\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   9186\u001B[0m \u001B[43m    \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   9187\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   9188\u001B[0m \u001B[43m    \u001B[49m\u001B[43mas_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mas_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   9189\u001B[0m \u001B[43m    \u001B[49m\u001B[43msort\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   9190\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroup_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   9191\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobserved\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobserved\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   9192\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdropna\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdropna\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   9193\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ana\\envs\\XGboost\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001B[0m, in \u001B[0;36mGroupBy.__init__\u001B[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001B[0m\n\u001B[0;32m   1326\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropna \u001B[38;5;241m=\u001B[39m dropna\n\u001B[0;32m   1328\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m grouper \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1329\u001B[0m     grouper, exclusions, obj \u001B[38;5;241m=\u001B[39m \u001B[43mget_grouper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1330\u001B[0m \u001B[43m        \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1331\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1332\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1333\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1334\u001B[0m \u001B[43m        \u001B[49m\u001B[43msort\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1335\u001B[0m \u001B[43m        \u001B[49m\u001B[43mobserved\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobserved\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mno_default\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobserved\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1336\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdropna\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropna\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1337\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1339\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m observed \u001B[38;5;129;01mis\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mno_default:\n\u001B[0;32m   1340\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(ping\u001B[38;5;241m.\u001B[39m_passed_categorical \u001B[38;5;28;01mfor\u001B[39;00m ping \u001B[38;5;129;01min\u001B[39;00m grouper\u001B[38;5;241m.\u001B[39mgroupings):\n",
      "File \u001B[1;32mC:\\ana\\envs\\XGboost\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001B[0m, in \u001B[0;36mget_grouper\u001B[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001B[0m\n\u001B[0;32m   1041\u001B[0m         in_axis, level, gpr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m, gpr, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1042\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1043\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(gpr)\n\u001B[0;32m   1044\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(gpr, Grouper) \u001B[38;5;129;01mand\u001B[39;00m gpr\u001B[38;5;241m.\u001B[39mkey \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1045\u001B[0m     \u001B[38;5;66;03m# Add key to exclusions\u001B[39;00m\n\u001B[0;32m   1046\u001B[0m     exclusions\u001B[38;5;241m.\u001B[39madd(gpr\u001B[38;5;241m.\u001B[39mkey)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'trade_date'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "构建股票资产组合",
   "id": "74e0900eca5ae58d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "def get_index_price(start_date, end_date, fields):\n",
    "    \"\"\"获取中证500指数价格数据\"\"\"\n",
    "    try:\n",
    "        # 读取CSV文件\n",
    "        df = pd.read_csv(r\"C:\\Users\\chanpi\\Desktop\\task\\中证500指数_201601-202506.csv\")\n",
    "\n",
    "        # 关键修复1：使用实际日期列名'trade_date'\n",
    "        if 'trade_date' in df.columns:\n",
    "            # 关键修复2：显式指定格式为'YYYYMMDD'，确保解析正确\n",
    "            df['trade_date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d', errors='coerce')\n",
    "            # 移除解析失败的无效日期\n",
    "            df = df.dropna(subset=['trade_date'])\n",
    "\n",
    "            # 按日期筛选（使用正确的列名）\n",
    "            start = pd.to_datetime(start_date)\n",
    "            end = pd.to_datetime(end_date)\n",
    "            mask = (df['trade_date'] >= start) & (df['trade_date'] <= end)\n",
    "            df = df.loc[mask]\n",
    "\n",
    "        # 字段筛选（保持不变）\n",
    "        if fields and len(fields) > 0:\n",
    "            available_fields = [field for field in fields if field in df.columns]\n",
    "            if available_fields:\n",
    "                df = df[available_fields]\n",
    "\n",
    "        # 若筛选后无数据，打印警告（便于调试）\n",
    "        if df.empty:\n",
    "            logging.warning(f\"[{start_date} to {end_date}] 无法获取指数数据（日期范围或格式错误）\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误：找不到文件 C:\\\\Users\\\\chanpi\\\\Desktop\\\\task\\\\中证500指数_201601-202506.csv\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"运行出错：{e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    # 测试用例1：正常情况\n",
    "    print(\"=== 测试1：正常情况 ===\")\n",
    "    result1 = get_index_price(\"2020-01-01\", \"2020-01-31\", [\"trade_date\", \"close\"])\n",
    "    print(f\"返回数据行数: {len(result1)}\")\n",
    "    if not result1.empty:\n",
    "        print(f\"列名: {result1.columns.tolist()}\")\n",
    "        print(f\"日期范围: {result1['trade_date'].min()} 到 {result1['trade_date'].max()}\")\n",
    "    \n",
    "    # 测试用例2：无数据情况\n",
    "    print(\"\\n=== 测试2：未来日期（应无数据） ===\")\n",
    "    result2 = get_index_price(\"2030-01-01\", \"2030-01-31\", [\"trade_date\", \"close\"])\n",
    "    print(f\"返回数据行数: {len(result2)}\")\n",
    "    \n",
    "    # 测试用例3：不存在的字段\n",
    "    print(\"\\n=== 测试3：不存在的字段 ===\")\n",
    "    result3 = get_index_price(\"2020-01-01\", \"2020-01-10\", [\"trade_date\", \"nonexistent_field\"])\n",
    "    if not result3.empty:\n",
    "        print(f\"实际返回的列: {result3.columns.tolist()}\")"
   ],
   "id": "cfd3bc8d08908f4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c719d3db36cff7fe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
